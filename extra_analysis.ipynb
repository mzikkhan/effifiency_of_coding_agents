{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfedafa",
   "metadata": {},
   "source": [
    "# Extra Analysis: 3-Way ANOVA\n",
    "This notebook analyses the effects for the factors Sentiment, Agent and User with different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2d92bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\austin\\anaconda3\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\austin\\anaconda3\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\austin\\anaconda3\\lib\\site-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\austin\\anaconda3\\lib\\site-packages (from fastparquet) (2024.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\austin\\anaconda3\\lib\\site-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\austin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow fastparquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb362a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646c1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists: hao-li/AIDev\n",
      "Files in dataset:\n",
      "  - .DS_Store\n",
      "  - .gitattributes\n",
      "  - README.md\n",
      "  - aidev_logo.png\n",
      "  - all_pull_request.parquet\n",
      "  - all_repository.parquet\n",
      "  - all_user.parquet\n",
      "  - data_table.md\n",
      "  - human_pr_task_type.parquet\n",
      "  - human_pull_request.parquet\n",
      "  - issue.parquet\n",
      "  - pr_comments.parquet\n",
      "  - pr_commit_details.parquet\n",
      "  - pr_commits.parquet\n",
      "  - pr_cumulative.png\n",
      "  - pr_review_comments.parquet\n",
      "  - pr_review_comments_v2.parquet\n",
      "  - pr_reviews.parquet\n",
      "  - pr_task_type.parquet\n",
      "  - pr_timeline.parquet\n",
      "  - pull_request.parquet\n",
      "  - related_issue.parquet\n",
      "  - repository.parquet\n",
      "  - schema.png\n",
      "  - user.parquet\n"
     ]
    }
   ],
   "source": [
    "# Test if we can access the dataset\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "try:\n",
    "    # Try to get dataset info\n",
    "    dataset_info = api.dataset_info(\"hao-li/AIDev\")\n",
    "    print(f\"Dataset exists: {dataset_info.id}\")\n",
    "    print(f\"Files in dataset:\")\n",
    "    files = api.list_repo_files(\"hao-li/AIDev\", repo_type=\"dataset\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing dataset: {e}\")\n",
    "    print(\"\\nThis could mean:\")\n",
    "    print(\"1. The dataset doesn't exist at 'hao-li/AIDev'\")\n",
    "    print(\"2. The dataset is private and you don't have access\")\n",
    "    print(\"3. The dataset name is incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ccaf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Ensure VADER lexicon is downloaded\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except LookupError:\n",
    "    print(\"Downloading VADER lexicon...\")\n",
    "    nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4c4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Downloading files from Hugging Face...\n",
      "  Downloading all_pull_request.parquet...\n",
      "  Downloading all_repository.parquet...\n",
      "  Downloading all_user.parquet...\n",
      "  Downloading pull_request.parquet...\n",
      "  Downloading repository.parquet...\n",
      "  Downloading user.parquet...\n",
      "  Downloading pr_comments.parquet...\n",
      "  Downloading pr_reviews.parquet...\n",
      "  Downloading pr_review_comments_v2.parquet...\n",
      "  Downloading pr_commits.parquet...\n",
      "  Downloading pr_commit_details.parquet...\n",
      "  Downloading related_issue.parquet...\n",
      "  Downloading issue.parquet...\n",
      "  Downloading pr_timeline.parquet...\n",
      "  Downloading pr_task_type.parquet...\n",
      "  Downloading human_pull_request.parquet...\n",
      "  Downloading human_pr_task_type.parquet...\n",
      "\n",
      "Loading parquet files into dataframes...\n",
      "\n",
      "✓ All datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\")\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Download files from Hugging Face to local cache\n",
    "    dataset_name = \"hao-li/AIDev\"\n",
    "    \n",
    "    # Download all required files\n",
    "    files_to_download = [\n",
    "        \"all_pull_request.parquet\",\n",
    "        \"all_repository.parquet\", \n",
    "        \"all_user.parquet\",\n",
    "        \"pull_request.parquet\",\n",
    "        \"repository.parquet\",\n",
    "        \"user.parquet\",\n",
    "        \"pr_comments.parquet\",\n",
    "        \"pr_reviews.parquet\",\n",
    "        \"pr_review_comments_v2.parquet\",\n",
    "        \"pr_commits.parquet\",\n",
    "        \"pr_commit_details.parquet\",\n",
    "        \"related_issue.parquet\",\n",
    "        \"issue.parquet\",\n",
    "        \"pr_timeline.parquet\",\n",
    "        \"pr_task_type.parquet\",\n",
    "        \"human_pull_request.parquet\",\n",
    "        \"human_pr_task_type.parquet\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Downloading files from Hugging Face...\")\n",
    "    file_paths = {}\n",
    "    for filename in files_to_download:\n",
    "        print(f\"  Downloading {filename}...\")\n",
    "        file_paths[filename] = hf_hub_download(repo_id=dataset_name, filename=filename, repo_type=\"dataset\")\n",
    "    \n",
    "    print(\"\\nLoading parquet files into dataframes...\")\n",
    "    all_pr_df = pd.read_parquet(file_paths[\"all_pull_request.parquet\"])\n",
    "    all_repo_df = pd.read_parquet(file_paths[\"all_repository.parquet\"])\n",
    "    all_user_df = pd.read_parquet(file_paths[\"all_user.parquet\"])\n",
    "\n",
    "    # Basic\n",
    "    pr_df = pd.read_parquet(file_paths[\"pull_request.parquet\"])\n",
    "    repo_df = pd.read_parquet(file_paths[\"repository.parquet\"])\n",
    "    user_df = pd.read_parquet(file_paths[\"user.parquet\"])\n",
    "    \n",
    "    # Comments and reviews\n",
    "    pr_comments_df = pd.read_parquet(file_paths[\"pr_comments.parquet\"])\n",
    "    pr_reviews_df = pd.read_parquet(file_paths[\"pr_reviews.parquet\"])\n",
    "    pr_review_comments_df = pd.read_parquet(file_paths[\"pr_review_comments_v2.parquet\"])\n",
    "    \n",
    "    # Commits\n",
    "    pr_commits_df = pd.read_parquet(file_paths[\"pr_commits.parquet\"])\n",
    "    pr_commit_details_df = pd.read_parquet(file_paths[\"pr_commit_details.parquet\"])\n",
    "    \n",
    "    # Related issues\n",
    "    related_issue_df = pd.read_parquet(file_paths[\"related_issue.parquet\"])\n",
    "    issue_df = pd.read_parquet(file_paths[\"issue.parquet\"])\n",
    "    \n",
    "    # Events\n",
    "    pr_timeline_df = pd.read_parquet(file_paths[\"pr_timeline.parquet\"])\n",
    "    \n",
    "    # Task type\n",
    "    pr_task_type_df = pd.read_parquet(file_paths[\"pr_task_type.parquet\"])\n",
    "    \n",
    "    # Human-PR\n",
    "    human_pr_df = pd.read_parquet(file_paths[\"human_pull_request.parquet\"])\n",
    "    human_pr_task_type_df = pd.read_parquet(file_paths[\"human_pr_task_type.parquet\"])\n",
    "\n",
    "    print(\"\\n✓ All datasets loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    pr_df, pr_timeline_df, pr_reviews_df = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a349601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing PR data...\n",
      "            id   state  lifecycle_hours\n",
      "0   3264933329  closed        76.038611\n",
      "1   3265118634  closed        17.258056\n",
      "2   3265640341  closed         0.100833\n",
      "3   3265709660  closed         0.635556\n",
      "16  3234102722  closed        35.815278\n"
     ]
    }
   ],
   "source": [
    "if pr_df is not None:\n",
    "    print(\"Preprocessing PR data...\")\n",
    "    closed_prs = pr_df[pr_df[\"state\"] == \"closed\"].copy()\n",
    "    closed_prs[\"created_at\"] = pd.to_datetime(closed_prs[\"created_at\"])\n",
    "    closed_prs[\"closed_at\"] = pd.to_datetime(closed_prs[\"closed_at\"])\n",
    "    closed_prs[\"lifecycle_hours\"] = (closed_prs[\"closed_at\"] - closed_prs[\"created_at\"]).dt.total_seconds() / 3600\n",
    "    pr_lifecycle = closed_prs[[\"id\", \"state\", \"lifecycle_hours\"]]\n",
    "    print(pr_lifecycle.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cdafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating iteration cycles...\n",
      "        pr_id  iteration_cycles\n",
      "0  2756921963                30\n",
      "1  2757103560                22\n",
      "2  2757124156                 7\n",
      "3  2757125491                 7\n",
      "4  2757179026                15\n"
     ]
    }
   ],
   "source": [
    "if pr_timeline_df is not None:\n",
    "    print(\"Calculating iteration cycles...\")\n",
    "    pr_iterations = (\n",
    "        pr_timeline_df\n",
    "        .groupby(\"pr_id\")\n",
    "        .size()\n",
    "        .reset_index(name=\"iteration_cycles\")\n",
    "    )\n",
    "    print(pr_iterations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1238cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment...\n",
      "Calculating VADER scores (this might take a moment)...\n",
      "Aggregating sentiment per PR...\n",
      "           id  mean_compound_score sentiment_category\n",
      "0  2760115428               0.0000            Neutral\n",
      "1  2766353261              -0.1779           Negative\n",
      "2  2768057346               0.4926           Positive\n",
      "3  2768057378               0.4199           Positive\n",
      "4  2768132850              -0.5267           Negative\n"
     ]
    }
   ],
   "source": [
    "if pr_reviews_df is not None:\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    # Extract relevant columns and drop missing bodies\n",
    "    reviews = pr_reviews_df[[\"pr_id\", \"body\"]].dropna().copy()\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_compound_score(text):\n",
    "        return sia.polarity_scores(text)[\"compound\"]\n",
    "    \n",
    "    # Calculate sentiment for each review\n",
    "    print(\"Calculating VADER scores (this might take a moment)...\")\n",
    "    reviews[\"compound_score\"] = reviews[\"body\"].apply(get_compound_score)\n",
    "    \n",
    "    # Aggregate by PR (Mean score)\n",
    "    print(\"Aggregating sentiment per PR...\")\n",
    "    pr_sentiment = reviews.groupby(\"pr_id\")[\"compound_score\"].mean().reset_index()\n",
    "    \n",
    "    # Classify sentiment\n",
    "    def classify_sentiment(score):\n",
    "        if score > 0.05:\n",
    "            return \"Positive\"\n",
    "        elif score < -0.05:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "            \n",
    "    pr_sentiment[\"sentiment_category\"] = pr_sentiment[\"compound_score\"].apply(classify_sentiment)\n",
    "    pr_sentiment.columns = [\"id\", \"mean_compound_score\", \"sentiment_category\"]\n",
    "    \n",
    "    print(pr_sentiment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db358d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging data...\n",
      "           id   state  lifecycle_hours       pr_id  iteration_cycles  \\\n",
      "0  3265709660  closed         0.635556  3265709660                11   \n",
      "1  3214555104  closed        47.635833  3214555104                30   \n",
      "2  3214724259  closed         0.004444  3214724259                12   \n",
      "3  3214876564  closed         0.938333  3214876564                30   \n",
      "4  3215868710  closed        13.475000  3215868710                30   \n",
      "\n",
      "   mean_compound_score sentiment_category  \n",
      "0             0.790600           Positive  \n",
      "1             0.332200           Positive  \n",
      "2             0.653100           Positive  \n",
      "3             0.499460           Positive  \n",
      "4             0.398367           Positive  \n"
     ]
    }
   ],
   "source": [
    "if pr_df is not None and pr_timeline_df is not None and pr_reviews_df is not None:\n",
    "    print(\"Merging data...\")\n",
    "    merged_df = pd.merge(\n",
    "        pr_lifecycle,\n",
    "        pr_iterations,\n",
    "        left_on=\"id\",\n",
    "        right_on=\"pr_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    final_df = pd.merge(\n",
    "        merged_df,\n",
    "        pr_sentiment,\n",
    "        on=\"id\",\n",
    "        how=\"inner\" # Only PRs with reviews/sentiment\n",
    "    )\n",
    "    print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f82e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"iteration_per_hour\"] = final_df[\"iteration_cycles\"] / final_df[\"lifecycle_hours\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 separate dataframes for each sentiment category\n",
    "positive_df = final_df[final_df[\"sentiment_category\"] == \"Positive\"]\n",
    "negative_df = final_df[final_df[\"sentiment_category\"] == \"Negative\"]\n",
    "neutral_df = final_df[final_df[\"sentiment_category\"] == \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed48fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the final_df with the agent column from closed_prs to see if there is any difference between AI agents and human agents\n",
    "merged_final_df = final_df.merge(\n",
    "    closed_prs[[\"id\", \"agent\"]], \n",
    "    left_on=\"id\", \n",
    "    right_on=\"id\", \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0fda30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the merged_final_df with the user_type column in the pr_reviews_df\n",
    "merged_final_df = merged_final_df.merge(\n",
    "    pr_reviews_df[[\"pr_id\", \"user_type\"]].drop_duplicates(), \n",
    "    left_on=\"id\", \n",
    "    right_on=\"pr_id\", \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "238b7952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sum_sq",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "df",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PR(>F)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3696918e-8e5e-4134-b99f-bc57a32bf359",
       "rows": [
        [
         "C(agent)",
         "16085836.23039664",
         "4.0",
         "35.717815620906734",
         "1.5915208394355085e-29"
        ],
        [
         "C(user_type)",
         "3790535.093465084",
         "1.0",
         "33.66679397546595",
         "6.887059122921445e-09"
        ],
        [
         "C(sentiment_category)",
         "512519.78232684534",
         "2.0",
         "2.2760504116814735",
         "0.1027808089000739"
        ],
        [
         "C(agent):C(user_type)",
         "5487237.669583985",
         "4.0",
         "12.184143897967685",
         "7.278689291354659e-10"
        ],
        [
         "C(agent):C(sentiment_category)",
         "6204049.48236992",
         "8.0",
         "6.887894801997704",
         "4.677021084206752e-09"
        ],
        [
         "C(user_type):C(sentiment_category)",
         "1030431.4961469817",
         "2.0",
         "4.5760458657169165",
         "0.01033276952050656"
        ],
        [
         "C(agent):C(user_type):C(sentiment_category)",
         "2178340.39349651",
         "8.0",
         "2.41844935569642",
         "0.013213213778853773"
        ],
        [
         "Residual",
         "652232280.0455884",
         "5793.0",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(agent)</th>\n",
       "      <td>1.608584e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.717816</td>\n",
       "      <td>1.591521e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(user_type)</th>\n",
       "      <td>3.790535e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.666794</td>\n",
       "      <td>6.887059e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(sentiment_category)</th>\n",
       "      <td>5.125198e+05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.276050</td>\n",
       "      <td>1.027808e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(agent):C(user_type)</th>\n",
       "      <td>5.487238e+06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.184144</td>\n",
       "      <td>7.278689e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(agent):C(sentiment_category)</th>\n",
       "      <td>6.204049e+06</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.887895</td>\n",
       "      <td>4.677021e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(user_type):C(sentiment_category)</th>\n",
       "      <td>1.030431e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.576046</td>\n",
       "      <td>1.033277e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(agent):C(user_type):C(sentiment_category)</th>\n",
       "      <td>2.178340e+06</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.418449</td>\n",
       "      <td>1.321321e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>6.522323e+08</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sum_sq      df          F  \\\n",
       "C(agent)                                     1.608584e+07     4.0  35.717816   \n",
       "C(user_type)                                 3.790535e+06     1.0  33.666794   \n",
       "C(sentiment_category)                        5.125198e+05     2.0   2.276050   \n",
       "C(agent):C(user_type)                        5.487238e+06     4.0  12.184144   \n",
       "C(agent):C(sentiment_category)               6.204049e+06     8.0   6.887895   \n",
       "C(user_type):C(sentiment_category)           1.030431e+06     2.0   4.576046   \n",
       "C(agent):C(user_type):C(sentiment_category)  2.178340e+06     8.0   2.418449   \n",
       "Residual                                     6.522323e+08  5793.0        NaN   \n",
       "\n",
       "                                                   PR(>F)  \n",
       "C(agent)                                     1.591521e-29  \n",
       "C(user_type)                                 6.887059e-09  \n",
       "C(sentiment_category)                        1.027808e-01  \n",
       "C(agent):C(user_type)                        7.278689e-10  \n",
       "C(agent):C(sentiment_category)               4.677021e-09  \n",
       "C(user_type):C(sentiment_category)           1.033277e-02  \n",
       "C(agent):C(user_type):C(sentiment_category)  1.321321e-02  \n",
       "Residual                                              NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('iteration_per_hour ~ C(agent) * C(user_type) * C(sentiment_category)', data=merged_final_df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d31560ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Multiple Comparison of Means - Tukey HSD, FWER=0.05        \n",
      "===================================================================\n",
      "   group1      group2     meandiff p-adj    lower    upper   reject\n",
      "-------------------------------------------------------------------\n",
      "Claude_Code      Copilot  -67.0081 0.1149 -143.1407   9.1244  False\n",
      "Claude_Code       Cursor  118.8639 0.0008   36.3567 201.3711   True\n",
      "Claude_Code        Devin  -49.4583 0.4148 -127.4152  28.4986  False\n",
      "Claude_Code OpenAI_Codex   33.2762 0.7535  -42.6197 109.1722  False\n",
      "    Copilot       Cursor   185.872    0.0  141.9737 229.7703   True\n",
      "    Copilot        Devin   17.5498 0.6379  -17.0464   52.146  False\n",
      "    Copilot OpenAI_Codex  100.2843    0.0   70.6226 129.9461   True\n",
      "     Cursor        Devin -168.3222    0.0 -215.3134 -121.331   True\n",
      "     Cursor OpenAI_Codex  -85.5877    0.0 -129.0743  -42.101   True\n",
      "      Devin OpenAI_Codex   82.7346    0.0   48.6621  116.807   True\n",
      "-------------------------------------------------------------------\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj  lower    upper   reject\n",
      "-----------------------------------------------------\n",
      "   Bot   User  -75.104   0.0 -92.8166 -57.3914   True\n",
      "-----------------------------------------------------\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1   group2  meandiff p-adj   lower    upper  reject\n",
      "---------------------------------------------------------\n",
      "Negative  Neutral -20.6843 0.3315 -54.8731 13.5046  False\n",
      "Negative Positive  -6.2283 0.8612 -34.2659 21.8092  False\n",
      " Neutral Positive  14.4559 0.4301 -12.8941  41.806  False\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Post-hoc tests (Tukey HSD)\n",
    "tukey_agent = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'],groups=merged_final_df['agent'],alpha=0.05)\n",
    "print(tukey_agent)\n",
    "\n",
    "# compare levels of 'user_type'\n",
    "tukey_user = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'],groups=merged_final_df['user_type'],alpha=0.05)\n",
    "print(tukey_user)\n",
    "\n",
    "# compare levels of 'sentiment_category'\n",
    "tukey_sentiment = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'],groups=merged_final_df['sentiment_category'],alpha=0.05)\n",
    "print(tukey_sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
