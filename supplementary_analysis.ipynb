{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e9dc88",
   "metadata": {},
   "source": [
    "# Supplementary Analysis: Interaction Effects (3-Way ANOVA)\n",
    "\n",
    "This notebook executes a 3-way ANOVA to analyze the interaction effects of **Sentiment** (Positive/Neutral/Negative), **Agent** (e.g., Copilot, Devin), and **User Type** (Bot/User) on the efficiency of pull requests (measured by iterations per hour).\n",
    "\n",
    "**Hypothesis**: There are significant interaction effects between the coding agent used, the sentiment of the review feedback, and the type of reviewer (human vs. bot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from huggingface_hub import hf_hub_download\n",
    "import traceback\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Ensure VADER lexicon is downloaded\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except LookupError:\n",
    "    print(\"Downloading VADER lexicon...\")\n",
    "    nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87576c60",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "We load the necessary datasets from the Hugging Face repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "\n",
    "try:\n",
    "    # Download files from Hugging Face to local cache\n",
    "    dataset_name = \"hao-li/AIDev\"\n",
    "    \n",
    "    # Download all required files\n",
    "    files_to_download = [\n",
    "        \"pull_request.parquet\",\n",
    "        \"pr_reviews.parquet\",\n",
    "        \"pr_timeline.parquet\",\n",
    "    ]\n",
    "    \n",
    "    file_paths = {}\n",
    "    for filename in files_to_download:\n",
    "        # print(f\"  Downloading {filename}...\")\n",
    "        file_paths[filename] = hf_hub_download(repo_id=dataset_name, filename=filename, repo_type=\"dataset\")\n",
    "    \n",
    "    print(\"Loading parquet files into dataframes...\")\n",
    "    \n",
    "    # Basic PR data\n",
    "    pr_df = pd.read_parquet(file_paths[\"pull_request.parquet\"])\n",
    "    \n",
    "    # Reviews\n",
    "    pr_reviews_df = pd.read_parquet(file_paths[\"pr_reviews.parquet\"])\n",
    "    \n",
    "    # Events/Timeline\n",
    "    pr_timeline_df = pd.read_parquet(file_paths[\"pr_timeline.parquet\"])\n",
    "    \n",
    "    print(\"âœ“ All datasets loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    traceback.print_exc()\n",
    "    pr_df, pr_timeline_df, pr_reviews_df = None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c03799",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data\n",
    "We calculate the lifecycle of each PR in hours and the number of iteration cycles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pr_df is not None:\n",
    "    print(\"Preprocessing PR data...\")\n",
    "    # Filter for closed PRs\n",
    "    closed_prs = pr_df[pr_df[\"state\"] == \"closed\"].copy()\n",
    "    \n",
    "    # Convert timestamps\n",
    "    closed_prs[\"created_at\"] = pd.to_datetime(closed_prs[\"created_at\"])\n",
    "    closed_prs[\"closed_at\"] = pd.to_datetime(closed_prs[\"closed_at\"])\n",
    "    \n",
    "    # Calculate lifecycle in hours\n",
    "    closed_prs[\"lifecycle_hours\"] = (closed_prs[\"closed_at\"] - closed_prs[\"created_at\"]).dt.total_seconds() / 3600\n",
    "    \n",
    "    pr_lifecycle = closed_prs[[\"id\", \"state\", \"lifecycle_hours\"]]\n",
    "    print(f\"Processed {len(pr_lifecycle)} closed PRs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pr_timeline_df is not None:\n",
    "    print(\"Calculating iteration cycles...\")\n",
    "    pr_iterations = (\n",
    "        pr_timeline_df\n",
    "        .groupby(\"pr_id\")\n",
    "        .size()\n",
    "        .reset_index(name=\"iteration_cycles\")\n",
    "    )\n",
    "    print(f\"Calculated iterations for {len(pr_iterations)} PRs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0761c82",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "We use VADER to analyze the sentiment of PR reviews, classifying them into Positive, Negative, or Neutral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pr_reviews_df is not None:\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    # Extract relevant columns and drop missing bodies\n",
    "    reviews = pr_reviews_df[[\"pr_id\", \"body\"]].dropna().copy()\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_compound_score(text):\n",
    "        return sia.polarity_scores(text)[\"compound\"]\n",
    "    \n",
    "    # Calculate sentiment for each review\n",
    "    print(\"Calculating VADER scores...\")\n",
    "    reviews[\"compound_score\"] = reviews[\"body\"].apply(get_compound_score)\n",
    "    \n",
    "    # Aggregate by PR (Mean score)\n",
    "    print(\"Aggregating sentiment per PR...\")\n",
    "    pr_sentiment = reviews.groupby(\"pr_id\")[\"compound_score\"].mean().reset_index()\n",
    "    \n",
    "    # Classify sentiment\n",
    "    def classify_sentiment(score):\n",
    "        if score > 0.05:\n",
    "            return \"Positive\"\n",
    "        elif score < -0.05:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "            \n",
    "    pr_sentiment[\"sentiment_category\"] = pr_sentiment[\"compound_score\"].apply(classify_sentiment)\n",
    "    pr_sentiment.columns = [\"id\", \"mean_compound_score\", \"sentiment_category\"]\n",
    "    \n",
    "    print(pr_sentiment.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0465c2",
   "metadata": {},
   "source": [
    "## 4. Construct Final Dataset\n",
    "We merge the lifecycle, iterations, sentiment, and agent/user information into a single DataFrame for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab57955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pr_df is not None and pr_timeline_df is not None and pr_reviews_df is not None:\n",
    "    print(\"Merging data...\")\n",
    "    \n",
    "    # 1. Merge Lifecycle and Iterations\n",
    "    merged_df = pd.merge(\n",
    "        pr_lifecycle,\n",
    "        pr_iterations,\n",
    "        left_on=\"id\",\n",
    "        right_on=\"pr_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # 2. Merge Sentiment\n",
    "    # We use inner join to keep only PRs that have reviews/sentiment data\n",
    "    final_df = pd.merge(\n",
    "        merged_df,\n",
    "        pr_sentiment,\n",
    "        on=\"id\",\n",
    "        how=\"inner\" \n",
    "    )\n",
    "    \n",
    "    # 3. Add Agent info (from closed_prs)\n",
    "    # Note: 'agent' column is assumed to exist in the loaded pull_request.parquet\n",
    "    merged_final_df = final_df.merge(\n",
    "        closed_prs[[\"id\", \"agent\"]], \n",
    "        left_on=\"id\", \n",
    "        right_on=\"id\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 4. Add User Type info (from pr_reviews_df)\n",
    "    # Note: merging on pr_id and user_type, dropping duplicates to avoid explosion if multiple types exist\n",
    "    formatted_reviews = pr_reviews_df[[\"pr_id\", \"user_type\"]].drop_duplicates()\n",
    "    \n",
    "    merged_final_df = merged_final_df.merge(\n",
    "        formatted_reviews, \n",
    "        left_on=\"id\", \n",
    "        right_on=\"pr_id\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Calculate Efficiency Metric\n",
    "    merged_final_df[\"iteration_per_hour\"] = merged_final_df[\"iteration_cycles\"] / merged_final_df[\"lifecycle_hours\"]\n",
    "\n",
    "    print(\"Final merged dataset ready.\")\n",
    "    print(merged_final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb5415",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis (3-Way ANOVA)\n",
    "We perform a 3-way ANOVA to test the effects of Agent, User Type, and Sentiment Category on `iteration_per_hour`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef726d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = ols('iteration_per_hour ~ C(agent) * C(user_type) * C(sentiment_category)', data=merged_final_df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display results\n",
    "anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e57a75",
   "metadata": {},
   "source": [
    "## 6. Post-hoc Analysis (Tukey HSD)\n",
    "We perform Tukey HSD tests to determine which specific groups differ significantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86331486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare agents\n",
    "print(\"--- Tukey HSD: Agent ---\")\n",
    "tukey_agent = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'], groups=merged_final_df['agent'], alpha=0.05)\n",
    "print(tukey_agent)\n",
    "\n",
    "# Compare user types\n",
    "print(\"\\n--- Tukey HSD: User Type ---\")\n",
    "tukey_user = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'], groups=merged_final_df['user_type'], alpha=0.05)\n",
    "print(tukey_user)\n",
    "\n",
    "# Compare sentiment categories\n",
    "print(\"\\n--- Tukey HSD: Sentiment Category ---\")\n",
    "tukey_sentiment = pairwise_tukeyhsd(endog=merged_final_df['iteration_per_hour'], groups=merged_final_df['sentiment_category'], alpha=0.05)\n",
    "print(tukey_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
